{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#‚ùì What's the optimal way to read partitioned parquet files into pandas?\n",
        "______________________________\n",
        "#### **[Upgini](https://github.com/upgini)  \"What's new\" monthly digest, November 2022**\n",
        "______________________________\n",
        "##Options\n",
        "1.   Baseline with Pandas - it can read parquet file with pyarrow under the hood, so why extra dependences?\n",
        "2.   [Vaex.io](https://github.com/vaexio/vaex) - based on pyarrow as well, read by chunks (out-of-core execution)\n",
        "3.   [Pola.rs](https://github.com/pola-rs/polars) - just implemented out-of-core execution (end of Oct'22) and has two modes:\n",
        "  - Pyarrow as a parquet format reader\n",
        "  - Rust based parquet reader (<- we'll test this )\n",
        "4.   [Pyarrow](https://arrow.apache.org/docs/python/install.html) - basic building block for other libs\n",
        "\n",
        "##Steps to read partitioned parquet files\n",
        "1. Read partitions\n",
        "2. Apply filters on values, if any (preferably @read operation)\n",
        "3. Sort (as order is not guaranteed for partitioned parquet files)\n",
        "4. Convert filtered and sorted dataset to pandas dataframe\n",
        "\n",
        "##Things to measure\n",
        "\n",
        "1.   Execution time\n",
        "2.   Memory consumption\n",
        "\n",
        "Let's install all the libraries, and a memory profiler, to estimate mem utilization"
      ],
      "metadata": {
        "id": "KyxMmbdC3EP8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFS-KfxS1FXU",
        "outputId": "eac5e19b-89ae-4aab-a7f6-66ccec9d8c50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12.2 MB 877 kB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.5 MB 46.0 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.2 MB 52.3 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 110 kB 66.2 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.1 MB 54.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 237 kB 58.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 51 kB 4.3 MB/s \n",
            "\u001b[?25h  Building wheel for aplus (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "%pip install -Uq pandas vaex-core polars memory_profiler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import polars as pl\n",
        "import pyarrow.parquet as pq\n",
        "import pyarrow.dataset as ds\n",
        "import vaex\n",
        "import gc\n",
        "import os\n",
        "import requests\n",
        "%load_ext memory_profiler"
      ],
      "metadata": {
        "id": "-2FZs8AO5fFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bechmark dataset\n",
        "For benchmark we'll take [Kaggle dataset](https://www.kaggle.com/datasets/wordsforthewise/lending-club) from LandingClub, it's listed under –°–°0 license.  \n",
        "\n",
        "*   Loan request rejections for 11 years of history - from 2007 till 2018; 24+mln of records\n",
        "*   Dataset has been converted to partitioned parquet files with ZSTD compression and year as a partition variable (12 files)\n",
        "\n",
        "Let's copy that into local file system for Colab, otherwise - stable measurement is not garanteed"
      ],
      "metadata": {
        "id": "W3O3-Di2Kj2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_url = \"https://github.com/upgini/upgini/raw/main/notebooks/digest202211/\"\n",
        "current_dir = os.getcwd()\n",
        "os.mkdir(current_dir+\"/data\")\n",
        "os.chdir(current_dir+\"/data\")\n",
        "\n",
        "for year in range(2007, 2019):\n",
        "    file_name = f\"bench_data_{year}.parquet\"\n",
        "    url = base_url + file_name\n",
        "    response = requests.get(url)\n",
        "    with open(f\"{file_name}\", \"wb\") as f:\n",
        "        f.write(response.content)"
      ],
      "metadata": {
        "id": "QvB16uQqPE42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Thanks to Vaex for dir parsing code üôè"
      ],
      "metadata": {
        "id": "NT7Qk-nUxmvm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import vaex.file\n",
        "import glob\n",
        "path=\"/content/data/*.parquet\"\n",
        "filenames = []\n",
        "path = vaex.file.stringyfy(path)\n",
        "naked_path, options = vaex.file.split_options(path)\n",
        "if glob.has_magic(naked_path):\n",
        "        filenames.extend(list(sorted(vaex.file.glob(path))))\n",
        "else:\n",
        "        filenames.append(path)"
      ],
      "metadata": {
        "id": "N-Y-GfpHxQeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Pandas `read_parquet` via *pyarrow*"
      ],
      "metadata": {
        "id": "-OrUjM8nOkqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "df = pd.read_parquet(\n",
        "    filenames,\n",
        "    engine=\"pyarrow\",\n",
        "    filters=[('Risk_Score','>',0)]\n",
        "    ).sort_values(by=\"Application Date\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XVAObUhUL6bG",
        "outputId": "fd041984-f1c8-4836-dc84-b7fd7a36538f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 1970.91 MiB, increment: 1606.54 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " %%memit\n",
        "del df\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i087M2OuOU68",
        "outputId": "34502343-9793-4cbf-a3e7-2b1867565152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 1884.49 MiB, increment: 0.00 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With `use_threads=True` pyarrow param\n"
      ],
      "metadata": {
        "id": "Z7VgNStWhufh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df = pd.read_parquet(\n",
        "    filenames,\n",
        "    engine=\"pyarrow\",\n",
        "    use_threads=True,\n",
        "    filters=[('Risk_Score','>',0)]\n",
        "    ).sort_values(by=\"Application Date\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0czntn-jOH_E",
        "outputId": "914f882f-e086-4b59-8c23-953257c699e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.8 s ¬± 726 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With `use_threads=False` pyarrow param"
      ],
      "metadata": {
        "id": "nIAmZQPmhyK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df = pd.read_parquet(\n",
        "    filenames,\n",
        "    engine=\"pyarrow\",\n",
        "    use_threads=False,\n",
        "    filters=[('Risk_Score','>',0)]\n",
        "    ).sort_values(by=\"Application Date\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYCAOc-hhtBP",
        "outputId": "4dd66d26-e8f4-4c87-be3c-36c1216bb6d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15.4 s ¬± 1.14 s per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Vaex `open`"
      ],
      "metadata": {
        "id": "QmRIurePdxi3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "df = vaex.open(filenames)\n",
        "df_pd = df[df[\"Risk_Score\"]>0].sort(by=\"Application Date\").to_pandas_df()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qu1o0yp-Pf6J",
        "outputId": "31055ee7-44c9-4cb6-e3ad-4d49e4c43438"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 6844.53 MiB, increment: 4954.29 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "del df_pd, df\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bl1z5jz9eEnS",
        "outputId": "7a1be211-d6e1-4bae-aafc-a7e060b136d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 6014.50 MiB, increment: 0.00 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df = vaex.open(filenames)\n",
        "df_pd = df[df[\"Risk_Score\"]>0].sort(by=\"Application Date\").to_pandas_df()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUS8pGp4YxNs",
        "outputId": "0f7a42a4-e0ea-4141-cac6-ceb9645b681d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.3 s ¬± 2.94 s per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Polars"
      ],
      "metadata": {
        "id": "zPSJMAN_jAkm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Full read with `read_parquet`"
      ],
      "metadata": {
        "id": "NgqwehalVZiv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "df = pl.read_parquet(\"/content/data/*.parquet\").filter(pl.col(\"Risk_Score\")>0)\n",
        "df_pd = df.sort(\"Application Date\").to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkfgWz_bjNwD",
        "outputId": "6a2be5cd-7d7b-44c6-a4cb-c89c86263b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 8532.83 MiB, increment: 5633.97 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "del df_pd, df\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "klDKCpyydUyq",
        "outputId": "05b03b7d-ebf6-4474-c7b0-a144e091b2c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 4325.67 MiB, increment: 0.00 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df = pl.read_parquet(\n",
        "    \"/content/data/*.parquet\"\n",
        "    ).filter(pl.col(\"Risk_Score\")>0).sort(\"Application Date\").to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VhniewVp34U",
        "outputId": "e4131618-f0e4-4c03-d287-5335cf19b3c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "14.3 s ¬± 1.82 s per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Stream/out-of-core `scan_parquet`"
      ],
      "metadata": {
        "id": "YIyoxofSo8nY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "df = pl.scan_parquet(\"/content/data/*.parquet\").filter(pl.col(\"Risk_Score\")>0)\n",
        "df_pd = df.sort(\"Application Date\").collect().to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y5NTVjwoO4p",
        "outputId": "cdff7270-466b-4cf8-8cc7-b0e1d34e4c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 5662.12 MiB, increment: 2201.96 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "del df_pd, df\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qD6gyJI0pGCd",
        "outputId": "b60dc109-4916-4dd5-d45b-77024f506ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 3825.09 MiB, increment: 0.00 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df = pl.scan_parquet(\n",
        "    \"/content/data/*.parquet\"\n",
        "    ).filter(pl.col(\"Risk_Score\")>0).sort(\"Application Date\").collect().to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qu-D23FlpDf_",
        "outputId": "f1caea62-f44e-4e9c-9cd5-844764a9965c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3 s ¬± 828 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Pyarrow"
      ],
      "metadata": {
        "id": "RiGkJ_wf5Hpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With `ParquetDataset` class"
      ],
      "metadata": {
        "id": "fTLJmqXKeQcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "df_pd = pq.ParquetDataset(\n",
        "    filenames,\n",
        "    use_legacy_dataset=False,\n",
        "    filters=[('Risk_Score','>',0)]\n",
        "    ).read().sort_by(\"Application Date\").to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EHJNcTiE5W-8",
        "outputId": "19597746-399c-4c7f-89a0-aa4b3aa22b58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 5398.18 MiB, increment: 1701.32 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "del df_pd\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zGmZsxg7rLd",
        "outputId": "923be45e-dfb1-41d5-c000-4f30001ab9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 3899.60 MiB, increment: -23.79 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df_pd = pq.ParquetDataset(\n",
        "    filenames,\n",
        "    use_legacy_dataset=False,\n",
        "    filters=[('Risk_Score','>',0)]\n",
        "    ).read().sort_by(\"Application Date\").to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUbtT45l7t8N",
        "outputId": "c6c46640-d4d1-4ef5-f38e-e4f9ec971c9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11 s ¬± 621 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### With `Dataset` class"
      ],
      "metadata": {
        "id": "dgPk5BnN8hnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "df_pd = ds.dataset(\n",
        "    filenames\n",
        "    ).scanner(filter=ds.field(\"Risk_Score\") > 0).to_table().sort_by(\"Application Date\").to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lE3Th2Tm9v0I",
        "outputId": "e06f6f67-1361-44e8-92d1-18a8aa295f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 5613.84 MiB, increment: 1720.72 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%memit\n",
        "del df_pd\n",
        "_ = gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXskakShDWhs",
        "outputId": "d5ac293c-f22c-4e13-c1cb-e8a1ac423fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "peak memory: 3919.64 MiB, increment: 0.00 MiB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "df_pd = ds.dataset(\n",
        "    filenames\n",
        "    ).scanner(filter=ds.field(\"Risk_Score\") > 0).to_table().sort_by(\"Application Date\").to_pandas()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_vw66JPBlrR",
        "outputId": "ae6e50f1-5711-4135-d9d3-00a42943916d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.3 s ¬± 675 ms per loop (mean ¬± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Conclusion\n",
        "\n",
        "1. **Pandas** - a solid option, not the fastest one, but for sure memory efficient. Memory increment ~1,6GB; execution ~15,5s\n",
        "2. **Vaex** - slowest one. We wan't be able to tune chunk size to speed up reading with out-of-core execution, probably in the future releases it's gonna be fixed. Memory increment ~5,0GB; execution ~24,5s\n",
        "3. **Polars** - with `scan_parquet` is among two fastest options. But it has issues with Decimal type support in parquet files (not tested here üòâ), so we'll keep looking on it's improvement with out-of-core execution and data types support.  Memory increment ~2,2GB; execution ~11,5s\n",
        "4. **Pyarrow** - with `ParquetDataset` class one of the two fastest options. And a second place on memory consumption with a small gap from Pandas. The most balanced choice for this scenario. Memory increment ~1,7GB; execution ~11,3s\n",
        "______________________________\n",
        "Thanks for reading! If you found this useful or interesting, please share with a friend.\n",
        "______________________________\n",
        "## üîó Useful links\n",
        "* Upgini Library [Documentation](https://github.com/upgini/upgini#readme)\n",
        "* More [Notebooks and Guides](https://github.com/upgini/upgini#briefcase-use-cases)\n",
        "* Kaggle public [Notebooks](https://www.kaggle.com/romaupgini/code)\n",
        "\n",
        "\n",
        "<sup>üòî Found mistype or a bug in code snippet? Our bad! <a href=\"https://github.com/upgini/upgini/issues/new?assignees=&title=readme%2Fbug\">\n",
        "Please report it here.</a></sup>"
      ],
      "metadata": {
        "id": "E0mbSNQ-Qe1M"
      }
    }
  ]
}